# [NeurIPS 2025] Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler


BDS (Bayesian Data Scheduler) is an adaptive defense framework against harmful fine-tuning for Large Language Models (LLMs). It implements a novel approach to data scheduler that enhances safety during the fine-tuning process.

The pipeline of BDS is shown below. A brief workflow is illustrated here.

![BDS pipeline](./figs/pipeline.png)

Representative experimental results:

- **Figure 1**: Data scheduling dynamics under low and high harmful ratios.
- **Figure 6**: Weight distributions under low and high harmful ratios.

![Result 1](./figs/result1.png)
![Result 2](./figs/result2.png)

## ğŸš€ Installation

### Environment Setup

1. **Install**
   ```bash
   conda env create -f /content/environment.yml
   conda activate bds
   pip install -e ./OpenRLHFBase/
   pip install -e .
   ```

2. **Datasets**

   Datasets json files are provided in `./run/scripts/datasets`.

   Or you can construct the datasets according the scripts in `run/sst2`, `run/gsm8k`, `run/agnews`, `run/alpaca`.

## âš™ï¸ Configuration


### Edit Configuration

Edit `./run/scripts/config.sh` with your actual values:

```bash
# API Keys and Tokens
export HUGGINGFACE_TOKEN="your_huggingface_token_here"
export WANDB_API_KEY="your_wandb_api_key_here"
export WANDB_PROJECT="your_project_name"

# Paths
export PREFIX_DIR="/path/to/your/bds/project"
```


## ğŸƒ Quick Start

### Training and Evaluation Template

Run the main script (including training, visualization, and evaluation):

```bash
bash ./run/scripts/0_train_eval_dbs.sh
```


## ğŸ“ Project Structure

```
bds/
â”œâ”€â”€ analysis/                    # Analysis and visualization tools
â”‚   â”œâ”€â”€ mountain_range_plotter.py    # Mountain Range visualization
â”‚   â”œâ”€â”€ score_analyzer.py           # Score analysis
â”‚   â””â”€â”€ llama2guard_analyzer.py     # LlamaGuard analysis
â”œâ”€â”€ bds/                        # Core BDS package
â”‚   â”œâ”€â”€ datasets/               # Dataset classes
â”‚   â”œâ”€â”€ models/                 # Model definitions
â”‚   â”œâ”€â”€ trainer/                # Training logic
â”‚   â””â”€â”€ utils/                  # Utilities
â”œâ”€â”€ run/                        # Run scripts and datasets
â”‚   â”œâ”€â”€ scripts/                # Training scripts
â”‚   â”‚   â”œâ”€â”€ config.sh           # Configuration template
â”‚   â”‚   â”œâ”€â”€ 0_train_eval_dbs.sh      # Main training+eval script
â”‚   â”‚   â””â”€â”€ datasets/           # Dataset files
â”‚   â”œâ”€â”€ sst2/                   # SST-2 dataset scripts
â”‚   â”œâ”€â”€ alpaca/                 # Alpaca dataset scripts
â”‚   â”œâ”€â”€ gsm8k/                  # GSM8K dataset scripts
â”‚   â”œâ”€â”€ agnews/                 # AG News dataset scripts
â”‚   â””â”€â”€ poison/                 # Poison evaluation scripts
â”œâ”€â”€ environment.yml            # Python dependencies
â””â”€â”€ setup.py                   # Package setup
```


## ğŸ”§ Analysis Tools

### 1. Score Analyzer (`analysis/score_analyzer.py`)

Analyzes and processes scoring data from training checkpoints.

**Usage:**
```bash
python analysis/score_analyzer.py --path /path/to/checkpoint --transformation softmax
```

**Parameters:**
- `--path`: Path to the checkpoint directory
- `--transformation`: Transformation type (softmax, linear, etc.)

### 2. Mountain Range Plotter (`analysis/mountain_range_plotter.py`)

Creates Mountain Range style visualizations of training progress.

**Usage:**
```bash
python analysis/mountain_range_plotter.py --path /path/to/checkpoint --step 100 --flag all
```

**Parameters:**
- `--path`: Path to the checkpoint directory
- `--step`: Step size for visualization
- `--flag`: Data filter (all, ft, harmful)
- `--transformation`: Transformation type

### 3. LlamaGuard Analyzer (`analysis/llama2guard_analyzer.py`) (Optional)

Analyzes model outputs using LlamaGuard for safety evaluation.

**Usage:**
```bash
python analysis/llama2guard_analyzer.py
```